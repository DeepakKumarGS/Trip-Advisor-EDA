{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trip Advisor Hotel Review Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.https://www.kaggle.com/ruchi798/how-do-you-recognize-fake-news\n",
    "\n",
    "2.https://www.kaggle.com/anokas/data-analysis-xgboost-starter-0-35460-lb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this kernel,I am going to do an analysis on the hotel reviews from Trip advisor dataset.The ratings scale is from 1-5 and there are 20491 reviews provided.\n",
    "\n",
    "#### Approach:\n",
    "\n",
    "I plan to do an n-gram and word cloud analysis to find out if the reviews could be easily differentiated with respect to their ratings.Then I plan to build basic models -TFIDF,Count vectorizer with either Logit or RandomForest.This is a multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from collections import Counter\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import spacy\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss,f1_score,confusion_matrix,plot_confusion_matrix\n",
    "from scipy.sparse import hstack,csr_matrix\n",
    "from tqdm import tqdm\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('../data/tripadvisor_hotel_reviews.csv')\n",
    "#data=pd.read_csv('../input/trip-advisor-hotel-reviews/tripadvisor_hotel_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning and handling missing values (if any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no null values in either of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "sns.countplot(data['Rating'])\n",
    "plt.title('Ratings Count in the dataset',fontsize=15)\n",
    "plt.xlabel('Rating',fontsize=8)\n",
    "plt.ylabel('Count',fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(data['Rating'].value_counts()/data.shape[0])*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data['Review'])[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44 % of the dataset has reviews with rating 5 while 29 % of the datset has reviews with rating 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## n-gram Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwrds=set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ruchi798/how-do-you-recognize-fake-news\n",
    "def get_bigram(df,n):\n",
    "   \n",
    "    vec=CountVectorizer(ngram_range=(2,2),stop_words=stopwrds).fit(df)\n",
    "    bag_of_words=vec.transform(df)\n",
    "    sum_words=bag_of_words.sum(0)\n",
    "    word_freq=[(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n",
    "    word_freq=sorted(word_freq,key=lambda x:x[1],reverse=True)\n",
    "    return word_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_rat1=get_bigram(data.loc[data['Rating']==1,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\n",
    "bigram_rat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_rat2=get_bigram(data.loc[data['Rating']==2,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\n",
    "bigram_rat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_rat3=get_bigram(data.loc[data['Rating']==3,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\n",
    "bigram_rat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_rat4=get_bigram(data.loc[data['Rating']==4,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\n",
    "bigram_rat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_rat5=get_bigram(data.loc[data['Rating']==5,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does'])),10)\n",
    "bigram_rat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for common words in highest rated reviews\n",
    "set([x[0] for x in bigram_rat3])\\\n",
    "&set([x[0] for x in bigram_rat4])\\\n",
    "&set([x[0] for x in bigram_rat5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for common words in least rated reviews\n",
    "set([x[0] for x in bigram_rat1])&set([x[0] for x in bigram_rat2])&set([x[0] for x in bigram_rat3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the bigrams for the ratings provides us the following insight:\n",
    "\n",
    "1.There are bigrams which are more common in all the reviews.\n",
    "\n",
    "2.great location,staff friendly,staff helpful,stayed nights,walking nights were more pronunced as the rating moves from 3 to 5 whereas stay away,customer service,make sure were few bigrams which were seen in reviews with rating 1-3.\n",
    "\n",
    "4.Punta cana and San Juan are names of places which were found in almost all of the reviews irrespective of the rating.\n",
    "\n",
    "For trigram analysis,Lets remove these common location names and check the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigram(df,n):\n",
    "   \n",
    "    vec=CountVectorizer(ngram_range=(3,3),stop_words=stopwrds).fit(df)\n",
    "    bag_of_words=vec.transform(df)\n",
    "    sum_words=bag_of_words.sum(0)\n",
    "    word_freq=[(word,sum_words[0,idx]) for word,idx in vec.vocabulary_.items()]\n",
    "    word_freq=sorted(word_freq,key=lambda x:x[1],reverse=True)\n",
    "    return word_freq[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_rat1=get_trigram(data.loc[data['Rating']==1,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\n",
    "trigram_rat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_rat2=get_trigram(data.loc[data['Rating']==2,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\n",
    "trigram_rat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_rat3=get_trigram(data.loc[data['Rating']==3,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\n",
    "trigram_rat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_rat4=get_trigram(data.loc[data['Rating']==4,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\n",
    "trigram_rat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigram_rat5=get_trigram(data.loc[data['Rating']==5,'Review'].apply(lambda x:\" \".join(sent for sent in x.split() if sent not in ['did','not','hotel','room','does','san','juan','punta','cana'])),10)\n",
    "trigram_rat5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for common words in highest rated reviews\n",
    "set([x[0] for x in trigram_rat3])\\\n",
    "&set([x[0] for x in trigram_rat4])\\\n",
    "&set([x[0] for x in trigram_rat5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check for common words in least rated reviews\n",
    "set([x[0] for x in trigram_rat1])\\\n",
    "&set([x[0] for x in trigram_rat2])\\\n",
    "&set([x[0] for x in trigram_rat3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to bigram analysis,trigram analysis presents us imporant insights:\n",
    "\n",
    "1.There are common words in highest rated reviews among the top 10 most common words. - 10 minute walk,flat screen tv,staff friendly helpful are a few.\n",
    "\n",
    "2.King size bed is the common trigram which appears in all the reviews across the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the n-gram analysis of words,it is seen that there are many words which appear across the reviews and this is a challenge since it might make our model difficult to distinguish between the ratings.\n",
    "\n",
    "Lets see if we can find any difference in the length,number of words etc across the rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['length']=data['Review'].apply(lambda x:len(x.split()))\n",
    "data['num_chars']=data['Review'].apply(lambda x:len(str(x)))\n",
    "data['num_punctuations']=data['Review'].apply(lambda x:len([c for c in x if x in string.punctuation]))\n",
    "data['num_stopwords']=data['Review'].apply(lambda x:len([c for c in str(x).lower().split() if c in stopwrds]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "plt.subplot(2,2,1)\n",
    "sns.boxplot(x='Rating',y='length',data=data,palette=sns.color_palette('colorblind'))\n",
    "plt.title('Distribution of Length by Rating',fontsize=15)\n",
    "plt.xlabel('Rating',fontsize=8)\n",
    "plt.ylabel('Length',fontsize=8)\n",
    "plt.subplot(2,2,2)\n",
    "sns.boxplot(x='Rating',y='num_chars',data=data,palette=sns.color_palette('colorblind'))\n",
    "plt.title('Distribution of Number of Characters by Rating',fontsize=15)\n",
    "plt.xlabel('Rating',fontsize=8)\n",
    "plt.ylabel('Num Chars',fontsize=8)\n",
    "plt.subplot(2,2,3)\n",
    "sns.boxplot(x='Rating',y='num_punctuations',data=data,palette=sns.color_palette('colorblind'))\n",
    "plt.title('Distribution of Num Punctuations by Rating',fontsize=15)\n",
    "plt.xlabel('Rating',fontsize=8)\n",
    "plt.ylabel('Num Punctuations',fontsize=8)\n",
    "plt.subplot(2,2,4)\n",
    "sns.boxplot(x='Rating',y='num_stopwords',data=data,palette=sns.color_palette('colorblind'))\n",
    "plt.title('Distribution of Stopwords by Rating',fontsize=15)\n",
    "plt.xlabel('Rating',fontsize=8)\n",
    "plt.ylabel('Num Stopwords',fontsize=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is a slight difference in the median length of the reviews with respect to each rating.But the difference is not pronunced much.Rating 5 has lesser median value compared to other ratings.\n",
    "\n",
    "* Similarly when the number of characters is considered,rating 5 has a smaller median value compared to other.But the difference is not easily distinguishable.\n",
    "\n",
    "* An empty plot for the punctuation indicates that there are no reviews having punctuations !!! Strange ..\n",
    "\n",
    "* The number of stopwords with respect to each rating is also dominated by lot of outliers.Those providing ratings of 5 are using more stopwords compared to other ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf=StratifiedKFold(n_splits=5,random_state=42,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=['length', 'num_chars', 'num_punctuations', 'num_stopwords']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_dict={1:0,\n",
    "              2:1,\n",
    "              3:2,\n",
    "              4:3,\n",
    "              5:4}\n",
    "data['Rating']=data['Rating'].map(encoding_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_sm',disable=['ner','parser','tagger'])\n",
    "\n",
    "def spacy_tokenizer(text):\n",
    "    tokens=[x.text for x in nlp(text)]\n",
    "    tokens=[tok.strip() for tok in tokens]\n",
    "    ## remove most common terms identified from n-gram analysis,\n",
    "    tokens=[tok for tok in tokens if tok!='' and tok not in ['did','not','hotel','room','does','san','juan','punta','cana']]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using TF-IDF and Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_tfidf=np.zeros((len(data),1))\n",
    "for i,(trn_idx,val_idx) in enumerate(kf.split(data['Review'],data['Rating'])):\n",
    "    print(f'Fold {i+1} Training ...')\n",
    "    train_x=data.iloc[trn_idx,].reset_index(drop=True)\n",
    "    valid_x=data.iloc[val_idx,].reset_index(drop=True)\n",
    "    train_y=data.iloc[trn_idx,1].values\n",
    "    valid_y=data.iloc[val_idx,1].values\n",
    "    \n",
    "    word_vectorizer=TfidfVectorizer(analyzer='word',tokenizer=spacy_tokenizer,\n",
    "                       token_pattern=r'\\w{1,}',\n",
    "                       stop_words=stopwrds,\n",
    "                      ngram_range=(1,3),max_features=8000)\n",
    "    \n",
    "    word_vectorizer.fit(list(train_x['Review'].values))\n",
    "    train_word_vec=word_vectorizer.transform(list(train_x['Review']))\n",
    "    valid_word_vec=word_vectorizer.transform(list(valid_x['Review']))\n",
    "    train_x_sparse=hstack((csr_matrix(train_x[feat]),train_word_vec))\n",
    "    valid_x_sparse=hstack((csr_matrix(valid_x[feat]),valid_word_vec))\n",
    "    rf=RandomForestClassifier(n_estimators=500,\n",
    "                             max_depth=20,\n",
    "                             max_features='auto',\n",
    "                             min_samples_split=5,\n",
    "                             bootstrap=True,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=42,\n",
    "                             verbose=False)\n",
    "    rf.fit(train_x_sparse,train_y)\n",
    "    preds=rf.predict(valid_x_sparse)\n",
    "    score=f1_score(valid_y,preds,average='macro')\n",
    "    print(f'Fold {i+1} f1 score {score}')\n",
    "    oof_preds_tfidf[val_idx]=preds.reshape(-1,1)\n",
    "oof_score_tfidf=f1_score(data['Rating'],oof_preds_tfidf.astype('int'),average='macro')\n",
    "print(f'Overall OOF f1 score {oof_score_tfidf}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Count Vectorizer and Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_preds_cv=np.zeros((len(data),1))\n",
    "for i,(trn_idx,val_idx) in enumerate(kf.split(data['Review'],data['Rating'])):\n",
    "    print(f'Fold {i+1} Training ...')\n",
    "    train_x=data.iloc[trn_idx,].reset_index(drop=True)\n",
    "    valid_x=data.iloc[val_idx,].reset_index(drop=True)\n",
    "    train_y=data.iloc[trn_idx,1].values\n",
    "    valid_y=data.iloc[val_idx,1].values\n",
    "    \n",
    "    count_vectorizer=CountVectorizer(analyzer='word',tokenizer=spacy_tokenizer,\n",
    "                       token_pattern=r'\\w{1,}',\n",
    "                       stop_words=stopwrds,\n",
    "                      ngram_range=(1,3),max_features=8000)\n",
    "    \n",
    "    count_vectorizer.fit(list(train_x['Review'].values))\n",
    "    train_word_vec=count_vectorizer.transform(list(train_x['Review']))\n",
    "    valid_word_vec=count_vectorizer.transform(list(valid_x['Review']))\n",
    "    train_x_sparse=hstack((csr_matrix(train_x[feat]),train_word_vec))\n",
    "    valid_x_sparse=hstack((csr_matrix(valid_x[feat]),valid_word_vec))\n",
    "    rf=RandomForestClassifier(n_estimators=500,\n",
    "                             max_depth=20,\n",
    "                             max_features='auto',\n",
    "                             min_samples_split=5,\n",
    "                             bootstrap=True,\n",
    "                             n_jobs=-1,\n",
    "                             random_state=42,\n",
    "                             verbose=False)\n",
    "    rf.fit(train_x_sparse,train_y)\n",
    "    preds=rf.predict(valid_x_sparse)\n",
    "    score=f1_score(valid_y,preds,average='macro')\n",
    "    print(f'Fold {i+1} f1 score {score}')\n",
    "    oof_preds_cv[val_idx]=preds.reshape(-1,1)\n",
    "oof_score_cv=f1_score(data['Rating'],oof_preds_cv.astype('int'),average='macro')\n",
    "print(f'Overall OOF f1 score {oof_score_cv}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
